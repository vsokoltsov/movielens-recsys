{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c78eeb",
   "metadata": {},
   "source": [
    "# 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78dcc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from metrics import evaluate_all\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba7cdd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(os.path.abspath('')).resolve().parents[0]\n",
    "DATA = os.path.join(ROOT, \"data\")\n",
    "INTERIM_DATA = os.path.join(DATA, \"interim\")\n",
    "RAW_DATA = os.path.join(DATA, \"raw\")\n",
    "MODELS = os.path.join(DATA, \"models\")\n",
    "MOVIELENS_PATH = os.path.join(RAW_DATA, \"ml-1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796a43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_parquet(os.path.join(INTERIM_DATA, 'users.parquet.gzip'))\n",
    "ratings_df = pd.read_parquet(os.path.join(INTERIM_DATA, 'ratings.parquet.gzip'))\n",
    "movies_df = pd.read_parquet(os.path.join(INTERIM_DATA, 'movies.parquet.gzip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5071a16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(963969, 4) (6040, 4) (30200, 4)\n",
      "Users in val: 6040 Users in test: 6040\n"
     ]
    }
   ],
   "source": [
    "def temporal_split_per_user(\n",
    "    ratings: pd.DataFrame,\n",
    "    n_val: int = 1,\n",
    "    n_test: int = 1,\n",
    "    min_train: int = 5,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Per-user time-based split:\n",
    "    - sort each user's interactions by timestamp\n",
    "    - last n_test -> test\n",
    "    - previous n_val -> val\n",
    "    - rest -> train\n",
    "    Users with too few interactions are kept in train only.\n",
    "    \"\"\"\n",
    "    r = ratings.sort_values([\"user_id\", \"timestamp\"]).copy()\n",
    "\n",
    "    r[\"rank\"] = r.groupby(\"user_id\").cumcount() + 1\n",
    "    r[\"user_cnt\"] = r.groupby(\"user_id\")[\"movie_id\"].transform(\"size\")\n",
    "\n",
    "    eligible = r[\"user_cnt\"] >= (min_train + n_val + n_test)\n",
    "\n",
    "    test_mask = eligible & (r[\"rank\"] > r[\"user_cnt\"] - n_test)\n",
    "    val_mask  = eligible & (r[\"rank\"] > r[\"user_cnt\"] - (n_test + n_val)) & ~test_mask\n",
    "    train_mask = ~test_mask & ~val_mask\n",
    "\n",
    "    train = r.loc[train_mask].drop(columns=[\"rank\", \"user_cnt\"])\n",
    "    val   = r.loc[val_mask].drop(columns=[\"rank\", \"user_cnt\"])\n",
    "    test  = r.loc[test_mask].drop(columns=[\"rank\", \"user_cnt\"])\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "train_df, val_df, test_df = temporal_split_per_user(ratings_df, n_val=1, n_test=5, min_train=5)\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)\n",
    "print(\"Users in val:\", val_df[\"user_id\"].nunique(), \"Users in test:\", test_df[\"user_id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1c13c",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8808e",
   "metadata": {},
   "source": [
    "### No intersections by lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30c7f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(map(tuple, train_df[[\"user_id\",\"movie_id\",\"timestamp\"]].values)).isdisjoint(\n",
    "       set(map(tuple, test_df[[\"user_id\",\"movie_id\",\"timestamp\"]].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e5b67",
   "metadata": {},
   "source": [
    "### Users from val/test have data in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ed6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train = set(train_df[\"user_id\"].unique())\n",
    "assert set(val_df[\"user_id\"].unique()).issubset(users_train)\n",
    "assert set(test_df[\"user_id\"].unique()).issubset(users_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378a286",
   "metadata": {},
   "source": [
    "### Order by time within a user: max(train) <= min(test) (for eligible users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36427674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000019</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>997454429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999988</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>997454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000172</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>997454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000167</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>997454486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000042</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>998315055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  movie_id  rating  timestamp\n",
       "31             1      3186       4  978300019\n",
       "22             1      1270       5  978300055\n",
       "27             1      1721       4  978300055\n",
       "37             1      1022       5  978300055\n",
       "24             1      2340       3  978300103\n",
       "...          ...       ...     ...        ...\n",
       "1000019     6040      2917       4  997454429\n",
       "999988      6040      1921       4  997454464\n",
       "1000172     6040      1784       3  997454464\n",
       "1000167     6040       161       3  997454486\n",
       "1000042     6040      1221       4  998315055\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = ratings_df.sort_values([\"user_id\",\"timestamp\"])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b6956f",
   "metadata": {},
   "source": [
    "## Baseline 1 - Popularity\n",
    "\n",
    "To verify the correctness and usefulness of more advanced recommendation models, it is crucial to establish a simple yet strong baseline.\n",
    "The popularity-based recommender serves as such a reference point.\n",
    "\n",
    "This baseline recommends the same set of items to all users, selecting the most popular movies according to the number of positive interactions in the training data (ratings ≥ 4). No personalization is involved.\n",
    "\n",
    "The popularity baseline provides a lower bound on model performance:\n",
    "* it represents the best result achievable without any personalization,\n",
    "* it reflects how much of the recommendation quality can be explained solely by globally popular items,\n",
    "* it helps detect implementation errors in more complex models — if a personalized model fails to outperform this baseline, it is likely misconfigured or ineffective.\n",
    "\n",
    "From a practical perspective, popularity-based recommendations are often used in real systems as:\n",
    "* a fallback strategy for cold-start users,\n",
    "* a simple default solution,\n",
    "* or a component of a larger ensemble.\n",
    "\n",
    "### Implementation details\n",
    "\n",
    "The model is implemented by:\n",
    "1. Filtering the training data to keep only positive interactions (rating ≥ 4).\n",
    "2. Counting the number of such interactions for each movie.\n",
    "3. Ranking movies by their popularity score.\n",
    "4. Returning the top-K most popular movies, excluding items already seen by the user (when applicable).\n",
    "\n",
    "Formally, for each item i, its popularity score is defined as:\n",
    "\n",
    "$$\n",
    "\\huge popularity(i) = \\sum_{u}\\mathbb{1}[r_{u,i} \\ge 4]\n",
    "$$\n",
    "\n",
    "The recommendation function returns the top-K items with the highest popularity scores.\n",
    "\n",
    "This baseline establishes a clear reference point:\n",
    "any personalized model (e.g. matrix factorization, ALS, neural models) is expected to surpass this score in terms of ranking metrics such as `Recall@K` and `NDCG@K`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "249e78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"interaction\"] = (train_df[\"rating\"] >= 4).astype(int)\n",
    "val_df[\"interaction\"] = (val_df[\"rating\"] >= 4).astype(int)\n",
    "test_df[\"interaction\"] = (test_df[\"rating\"] >= 4).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae7a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = train_df[train_df[\"interaction\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62fb17e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "2858    2766\n",
       "260     2557\n",
       "1196    2461\n",
       "1198    2213\n",
       "2028    2194\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_popularity = (\n",
    "    train_pos\n",
    "    .groupby(\"movie_id\")\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "item_popularity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd26ef24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2858, 260, 1196, 1198, 2028, 593, 2571, 1210, 527, 2762]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_k_popular(item_popularity, k=10):\n",
    "    return item_popularity.index[:k].tolist()\n",
    "\n",
    "top10_popular = get_top_k_popular(item_popularity, k=10)\n",
    "top10_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31709f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_popularity(\n",
    "    user_id: int,\n",
    "    train_df: pd.DataFrame,\n",
    "    item_popularity: pd.Series,\n",
    "    k: int = 10,\n",
    "):\n",
    "    seen_items = set(\n",
    "        train_df.loc[train_df[\"user_id\"] == user_id, \"movie_id\"]\n",
    "    )\n",
    "\n",
    "    recs = []\n",
    "    for movie_id in item_popularity.index:\n",
    "        if movie_id not in seen_items:\n",
    "            recs.append(movie_id)\n",
    "        if len(recs) == k:\n",
    "            break\n",
    "\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a192a21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2858, 1196, 1198, 593, 2571, 1210, 589, 318, 858, 110]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_popularity(1, train_df, item_popularity, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb4f82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"interaction\"] = (test_df[\"rating\"] >= 4).astype(int)\n",
    "\n",
    "test_pos = test_df[test_df[\"interaction\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30c7bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(recommended, relevant):\n",
    "    if len(relevant) == 0:\n",
    "        return None\n",
    "    return len(set(recommended) & set(relevant)) / len(relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1848fb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052443123836965"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_popularity(\n",
    "    train_df,\n",
    "    test_pos,\n",
    "    item_popularity,\n",
    "    k=10,\n",
    "):\n",
    "    recalls = []\n",
    "\n",
    "    for user_id, group in test_pos.groupby(\"user_id\"):\n",
    "        relevant_items = group[\"movie_id\"].tolist()\n",
    "        recs = recommend_popularity(\n",
    "            user_id, train_df, item_popularity, k\n",
    "        )\n",
    "        r = recall_at_k(recs, relevant_items)\n",
    "        if r is not None:\n",
    "            recalls.append(r)\n",
    "\n",
    "    return sum(recalls) / len(recalls)\n",
    "\n",
    "\n",
    "recall10 = evaluate_popularity(\n",
    "    train_df, test_pos, item_popularity, k=10\n",
    ")\n",
    "\n",
    "recall10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2242d625",
   "metadata": {},
   "source": [
    "## Baseline 2 - Item-based Collaborative Filtering (kNN)\n",
    "\n",
    "This baseline implements **item–item collaborative filtering** using a k-nearest neighbors approach.\n",
    "\n",
    "Instead of learning latent factors (as in matrix factorization), \n",
    "it computes **similarity between items** based on how often they are co-consumed by the same users.\n",
    "\n",
    "### Training (fit) stage:\n",
    "\n",
    "1. Convert explicit ratings into implicit positive interactions (`rating >= threshold`).\n",
    "2. Build a sparse user–item interaction matrix $\\large X_{ui}$ where $\\large X_{ui}=1$ if the user liked the item.\n",
    "3. Compute an item–item co-occurrence matrix $\\large C = X_{iu} X_{ui}$ and transform it into cosine similarity:\n",
    "\n",
    "$$\n",
    "\\huge S_{ij} = \\frac{C_{ij}}{\\|i\\|\\|j\\|}\n",
    "$$\n",
    "\n",
    "4. Keep only top `k_neighbors` similarities per item for efficiency (sparse top-k pruning).\n",
    "\n",
    "### Inference (recommend) stage:\n",
    "\n",
    "For a given user, scores for candidate items are computed as a weighted sum of similarities to items the user already liked:\n",
    "\n",
    "$$\n",
    "\\huge score(u, i) = \\sum_{j \\in I_u} S_{ij}\n",
    "$$\n",
    "\n",
    "Already-seen items are filtered out, and the top-K items are returned.\n",
    "\n",
    "This baseline is useful because it is:\n",
    "* **personalized** (unlike popularity),\n",
    "* **interpretable** (recommendations can be explained by similar watched items),\n",
    "* a strong classical CF reference point to compare against ALS and neural models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e4a25c",
   "metadata": {},
   "source": [
    "For model's evaluation, let us define appropriate functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "037d099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(recommended, relevant, k=10):\n",
    "    rel = set(relevant)\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended[:k], start=1):\n",
    "        if item in rel:\n",
    "            dcg += 1.0 / math.log2(i + 1)\n",
    "    ideal_hits = min(len(rel), k)\n",
    "    idcg = sum(1.0 / math.log2(i + 1) for i in range(1, ideal_hits + 1))\n",
    "    return 0.0 if idcg == 0 else dcg / idcg\n",
    "    \n",
    "def evaluate_model(recommend_fn, test_df, k=10, threshold=4):\n",
    "    tmp = test_df.copy()\n",
    "    tmp[\"interaction\"] = (tmp[\"rating\"] >= threshold).astype(np.int8)\n",
    "    test_pos = tmp[tmp[\"interaction\"] == 1]\n",
    "\n",
    "    recalls, ndcgs = [], []\n",
    "    for user_id, g in test_pos.groupby(\"user_id\"):\n",
    "        relevant = g[\"movie_id\"].tolist()\n",
    "        recs = recommend_fn(user_id, k=k)\n",
    "        if not recs:\n",
    "            continue\n",
    "\n",
    "        recalls.append(len(set(recs) & set(relevant)) / len(relevant))\n",
    "        ndcgs.append(ndcg_at_k(recs, relevant, k=k))\n",
    "\n",
    "    return float(np.mean(recalls)), float(np.mean(ndcgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec1eeb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemKNNRecommender:\n",
    "    def __init__(self, k_neighbors=200, threshold=4):\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.user2idx = None\n",
    "        self.item2idx = None\n",
    "        self.idx2item = None\n",
    "        self.X_ui = None          # user-item\n",
    "        self.S_ii = None          # item-item similarity (sparse)\n",
    "\n",
    "    def fit(self, ratings_df: pd.DataFrame):\n",
    "        df = ratings_df.copy()\n",
    "        df = df[df[\"rating\"] >= self.threshold][[\"user_id\", \"movie_id\"]]\n",
    "\n",
    "        # factorize\n",
    "        u_codes, u_uniques = pd.factorize(df[\"user_id\"], sort=True)\n",
    "        i_codes, i_uniques = pd.factorize(df[\"movie_id\"], sort=True)\n",
    "\n",
    "        self.user2idx = {int(u): int(i) for i, u in enumerate(u_uniques)}\n",
    "        self.item2idx = {int(m): int(i) for i, m in enumerate(i_uniques)}\n",
    "        self.idx2item = {int(i): int(m) for i, m in enumerate(i_uniques)}\n",
    "\n",
    "        n_users = len(u_uniques)\n",
    "        n_items = len(i_uniques)\n",
    "\n",
    "        self.X_ui = csr_matrix(\n",
    "            (np.ones(len(df), dtype=np.float32), (u_codes, i_codes)),\n",
    "            shape=(n_users, n_items),\n",
    "        )\n",
    "\n",
    "        self._build_similarity()\n",
    "\n",
    "    def _build_similarity(self):\n",
    "        X_iu = self.X_ui.T.tocsr()              # (n_items, n_users)\n",
    "        S = (X_iu @ X_iu.T).tocsr()             # co-occurrence\n",
    "\n",
    "        # cosine normalize\n",
    "        item_norm = np.sqrt(S.diagonal())\n",
    "        item_norm[item_norm == 0] = 1.0\n",
    "        D_inv = diags(1.0 / item_norm)\n",
    "        S = (D_inv @ S @ D_inv).tocsr()\n",
    "        S.setdiag(0.0)\n",
    "\n",
    "        # leaving only top-k_neighbors for each item (speeds up and improves)\n",
    "        if self.k_neighbors is not None:\n",
    "            S = self._topk_per_row(S, self.k_neighbors)\n",
    "\n",
    "        S.eliminate_zeros()\n",
    "        self.S_ii = S\n",
    "\n",
    "    @staticmethod\n",
    "    def _topk_per_row(S: csr_matrix, k: int) -> csr_matrix:\n",
    "        S = S.tolil()\n",
    "        for i in range(S.shape[0]):\n",
    "            row_data = np.array(S.data[i])\n",
    "            row_cols = np.array(S.rows[i])\n",
    "            if len(row_data) > k:\n",
    "                idx = np.argpartition(-row_data, k)[:k]\n",
    "                S.data[i] = row_data[idx].tolist()\n",
    "                S.rows[i] = row_cols[idx].tolist()\n",
    "        return S.tocsr()\n",
    "\n",
    "    def recommend(self, user_id: int, k: int = 10):\n",
    "        if user_id not in self.user2idx:\n",
    "            return []\n",
    "\n",
    "        uidx = self.user2idx[user_id]\n",
    "        user_row = self.X_ui.getrow(uidx)\n",
    "        seen = set(user_row.indices)\n",
    "\n",
    "        if not seen:\n",
    "            return []\n",
    "\n",
    "        scores = (user_row @ self.S_ii).toarray().ravel()\n",
    "        if seen:\n",
    "            scores[list(seen)] = -np.inf\n",
    "\n",
    "        top = np.argpartition(-scores, k)[:k]\n",
    "        top = top[np.argsort(-scores[top])]\n",
    "        return [self.idx2item[int(i)] for i in top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5319bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1196, 1198, 318, 593, 1197, 1265, 1307, 1259, 2396, 457]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = ItemKNNRecommender(k_neighbors=200, threshold=4)\n",
    "knn.fit(train_df)\n",
    "recs = knn.recommend(1, k=10)\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6695654a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06281289393120834, 0.045003165066709226)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_knn(user_id: int, k: int = 10):\n",
    "    return knn.recommend(user_id, k=k)\n",
    "\n",
    "recall10_knn, ndcg10_knn = evaluate_model(recommend_knn, test_df, k=10, threshold=4)\n",
    "recall10_knn, ndcg10_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96523b",
   "metadata": {},
   "source": [
    "## Baseline 3 — Matrix Factorization (ALS for Implicit Feedback)\n",
    "\n",
    "The popularity baseline establishes the level of performance that can be achieved **without personalization**,\n",
    "by recommending the same globally popular items to all users.\n",
    "\n",
    "The next step is to introduce personalization by leveraging historical user–item interactions through **collaborative filtering**.\n",
    "\n",
    "Matrix Factorization (MF) is a classical and widely used approach to collaborative filtering.\n",
    "\n",
    "It assumes that both users and items can be represented in a shared **latent factor space**, where user preferences and item characteristics are encoded as dense vectors.\n",
    "\n",
    "The relevance of an item for a given user is then estimated by the dot product of their corresponding latent vectors:\n",
    "\n",
    "$$\n",
    "\\huge score(u, i) = \\mathbf{p}_u^\\top \\mathbf{q}_i\n",
    "$$\n",
    "\n",
    "where:\n",
    "* $\\large \\mathbf{p}_u$ is the latent embedding of user `u`,\n",
    "* $\\large \\mathbf{q}_i$ is the latent embedding of item `i`.\n",
    "\n",
    "In this project, matrix factorization is implemented using [Alternating Least Squares (ALS)](https://benfred.github.io/implicit/api/models/cpu/als.html) from the [implicit](https://benfred.github.io/implicit/index.html) library, which is specifically designed for implicit feedback scenarios. ALS is chosen because it:\n",
    "* efficiently scales to large, sparse interaction matrices,\n",
    "* provides a strong and stable baseline for implicit recommendation tasks,\n",
    "* is commonly used as a production-grade retrieval model.\n",
    "\n",
    "### Purpose of this baseline\n",
    "\n",
    "The ALS baseline answers the following question:\n",
    "\n",
    "* **How much improvement over the popularity baseline can be achieved by adding personalization based solely on user–item interaction data?**\n",
    "\n",
    "This baseline serves several important roles:\n",
    "* If ALS significantly outperforms the popularity model, it confirms that collaborative filtering is effective for this dataset.\n",
    "* If ALS fails to outperform popularity, it often indicates issues such as data leakage, incorrect train–test splitting, or implementation errors.\n",
    "* ALS provides a strong classical reference point against which more complex neural models should be compared.\n",
    "\n",
    "Because ALS is already a powerful model, neural approaches are not expected to outperform it unless they \n",
    "incorporate additional signals (e.g. side features, hard negative sampling, or multi-stage retrieval and ranking).\n",
    "\n",
    "### Relationship to other models\n",
    "\n",
    "* **Baseline 1 — Popularity**: non-personalized recommendations based solely on global item popularity; establishes a lower bound on achievable performance.\n",
    "* **Baseline 2 — Item-based Collaborative Filtering (kNN)**: personalized recommendations using memory-based collaborative signals by leveraging item–item similarities derived from user interaction histories.\n",
    "\n",
    "In this progression, Item-based kNN serves as the first personalized baseline, demonstrating the benefit of collaborative filtering without learning latent representations.\n",
    "\n",
    "ALS then acts as a bridge between memory-based heuristics and deep learning models, providing a strong, \n",
    "scalable latent-factor baseline against which the benefits of increased model complexity can be quantitatively evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25835317",
   "metadata": {},
   "source": [
    "### Implementation details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3777acb7",
   "metadata": {},
   "source": [
    "Explicit ratings are converted into implicit positive interactions.\n",
    "\n",
    "Only positive feedback (rating >= 4) is retained. \n",
    "\n",
    "The absence of an interaction is treated as unknown rather than negative feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47e87501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tmp = train_df.copy()\n",
    "train_tmp[\"interaction\"] = (train_tmp[\"rating\"] >= 4).astype(np.int8)\n",
    "train_pos = train_tmp[train_tmp[\"interaction\"] == 1][[\"user_id\", \"movie_id\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e86e9",
   "metadata": {},
   "source": [
    "### Index mapping and factorization\n",
    "\n",
    "User and item identifiers are mapped to consecutive integer indices to enable efficient matrix operations.\n",
    "\n",
    "Bidirectional mappings (user2idx, idx2item, etc.) are stored to convert between internal indices and original identifiers during inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "193b38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_codes, u_uniques = pd.factorize(train_pos[\"user_id\"], sort=True)\n",
    "i_codes, i_uniques = pd.factorize(train_pos[\"movie_id\"], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e803f41",
   "metadata": {},
   "source": [
    "### Sparse interaction matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4ec0d",
   "metadata": {},
   "source": [
    "A sparse user–item interaction matrix $\\large X_{ui}$ is constructed.\n",
    "\n",
    "Here, $\\large X_{ui} = 1$ indicates a positive interaction, and zero indicates no observed interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d42663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos[\"u_idx\"] = u_codes.astype(np.int32)\n",
    "train_pos[\"i_idx\"] = i_codes.astype(np.int32)\n",
    "\n",
    "user2idx = pd.Series(np.arange(len(u_uniques)), index=u_uniques).to_dict()\n",
    "idx2user = pd.Series(u_uniques).to_dict()\n",
    "\n",
    "idx2item = pd.Series(i_uniques).to_dict()          # i_idx -> movie_id\n",
    "item2idx = pd.Series(np.arange(len(i_uniques)), index=i_uniques).to_dict()\n",
    "\n",
    "X_ui = csr_matrix(\n",
    "    (np.ones(len(train_pos), dtype=np.float32),\n",
    "     (train_pos[\"u_idx\"].to_numpy(), train_pos[\"i_idx\"].to_numpy())),\n",
    "    shape=(len(u_uniques), len(i_uniques)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58594c3",
   "metadata": {},
   "source": [
    "#### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1ffe156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_ui shape: (6038, 3525)\n",
      "max i_idx: 3524 idx2item max key: 3524\n"
     ]
    }
   ],
   "source": [
    "print(\"X_ui shape:\", X_ui.shape)\n",
    "print(\"max i_idx:\", train_pos[\"i_idx\"].max(), \"idx2item max key:\", max(idx2item.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209b9139",
   "metadata": {},
   "source": [
    "### ALS training\n",
    "\n",
    "The ALS model is trained on the interaction matrix.\n",
    "\n",
    "The model learns:\n",
    "* `user_factors`: a matrix of shape (`n_users`, `factors`),\n",
    "* `item_factors`: a matrix of shape (`n_items`, `factors`).\n",
    "\n",
    "Sanity checks are applied to ensure that the orientation of the matrix is correct and that factor dimensions match the expected number of users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b2894e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d6c298305a48b489b44d1ac56c8102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X_ui: (n_users, n_items)\n",
    "n_users, n_items = X_ui.shape\n",
    "\n",
    "# item_users: (n_items, n_users)\n",
    "item_users = X_ui\n",
    "\n",
    "als = AlternatingLeastSquares(\n",
    "    factors=64,\n",
    "    regularization=0.01,\n",
    "    iterations=20,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "als.fit(item_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91b20e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_ui: (6038, 3525)\n",
      "item_users: (6038, 3525)\n",
      "als.user_factors: (6038, 64)\n",
      "als.item_factors: (3525, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_ui:\", X_ui.shape)\n",
    "print(\"item_users:\", item_users.shape)\n",
    "print(\"als.user_factors:\", als.user_factors.shape)\n",
    "print(\"als.item_factors:\", als.item_factors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f63c33",
   "metadata": {},
   "source": [
    "#### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bb901e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert als.user_factors.shape[0] == n_users, \"ALS thinks n_users is different: you fitted on wrong matrix.\"\n",
    "assert als.item_factors.shape[0] == n_items, \"ALS thinks n_items is different: you fitted on wrong matrix.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66fbb89",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b54d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_als(user_id: int, k: int = 10):\n",
    "    if user_id not in user2idx:\n",
    "        return []\n",
    "\n",
    "    uidx = user2idx[user_id]\n",
    "\n",
    "    seen_movie_ids = set(train_df.loc[train_df[\"user_id\"] == user_id, \"movie_id\"])\n",
    "    seen_iidx = {item2idx[m] for m in seen_movie_ids if m in item2idx}\n",
    "\n",
    "    item_idxs, scores = als.recommend(uidx, X_ui[uidx], N=k + 200)\n",
    "\n",
    "    recs = []\n",
    "    n_items = X_ui.shape[1]\n",
    "\n",
    "    for ii in item_idxs:\n",
    "        ii = int(ii)\n",
    "\n",
    "        if ii < 0 or ii >= n_items:\n",
    "            raise RuntimeError(\n",
    "                f\"ALS returned out-of-range item index {ii}, but n_items={n_items}. \"\n",
    "                \"This means the model and X_ui are from different runs.\"\n",
    "            )\n",
    "\n",
    "        if ii in seen_iidx:\n",
    "            continue\n",
    "\n",
    "        recs.append(idx2item[ii])\n",
    "        if len(recs) == k:\n",
    "            break\n",
    "\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ca599",
   "metadata": {},
   "source": [
    "#### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0984bf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.012137583288312622 0.04015847289753287\n",
      "5 0.056777117474038054 0.04832256101932624\n",
      "10 0.09471757008223783 0.0656072331693472\n",
      "20 0.15718830662104566 0.08786627684744384\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 5, 10, 20]:\n",
    "    r, n = evaluate_model(recommend_als, test_df, k=k)\n",
    "    print(k, r, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a1b1b",
   "metadata": {},
   "source": [
    "## Tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fac177d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Any\n",
    "def build_X_ui(\n",
    "    train_df: pd.DataFrame,\n",
    "    threshold: int = 4,\n",
    "    user_col: str = \"user_id\",\n",
    "    item_col: str = \"movie_id\",\n",
    ") -> Tuple[csr_matrix, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Build sparse user-item matrix X_ui from train_df using implicit positives (rating >= threshold).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_ui : csr_matrix of shape (n_users, n_items)\n",
    "        Binary interaction matrix for positive feedback.\n",
    "    artifacts : dict\n",
    "        Mappings and factorized training positives.\n",
    "    \"\"\"\n",
    "    # 1) users/items universe from TRAIN (not only positives)\n",
    "    u_uniques = np.sort(train_df[user_col].unique())\n",
    "    i_uniques = np.sort(train_df[item_col].unique())\n",
    "\n",
    "    user2idx = {int(u): int(i) for i, u in enumerate(u_uniques)}\n",
    "    idx2user = {int(i): int(u) for i, u in enumerate(u_uniques)}\n",
    "    item2idx = {int(m): int(i) for i, m in enumerate(i_uniques)}\n",
    "    idx2item = {int(i): int(m) for i, m in enumerate(i_uniques)}\n",
    "\n",
    "    n_users, n_items = len(u_uniques), len(i_uniques)\n",
    "\n",
    "    # 2) only positive interactions become 1s in X_ui\n",
    "    pos = train_df.loc[train_df[\"rating\"] >= threshold, [user_col, item_col]].copy()\n",
    "    if pos.empty:\n",
    "        X_ui = csr_matrix((n_users, n_items), dtype=np.float32)\n",
    "        artifacts = dict(user2idx=user2idx, idx2user=idx2user, item2idx=item2idx, idx2item=idx2item,\n",
    "                         n_users=n_users, n_items=n_items)\n",
    "        return X_ui, artifacts\n",
    "\n",
    "    rows = pos[user_col].map(user2idx).to_numpy(dtype=np.int32)\n",
    "    cols = pos[item_col].map(item2idx).to_numpy(dtype=np.int32)\n",
    "    data = np.ones(len(pos), dtype=np.float32)\n",
    "\n",
    "    X_ui = csr_matrix((data, (rows, cols)), shape=(n_users, n_items), dtype=np.float32)\n",
    "\n",
    "    artifacts = dict(user2idx=user2idx, idx2user=idx2user, item2idx=item2idx, idx2item=idx2item,\n",
    "                     n_users=n_users, n_items=n_items)\n",
    "    return X_ui, artifacts\n",
    "\n",
    "\n",
    "def recommend_als_from_artifacts(\n",
    "    als_model,\n",
    "    X_ui: csr_matrix,\n",
    "    artifacts: Dict[str, Any],\n",
    "    user_id: int,\n",
    "    k: int = 10,\n",
    "    filter_already_liked: bool = True,\n",
    ") -> List[int]:\n",
    "    user2idx = artifacts[\"user2idx\"]\n",
    "    idx2item = artifacts[\"idx2item\"]\n",
    "    n_items = artifacts[\"n_items\"]\n",
    "\n",
    "    if user_id not in user2idx:\n",
    "        return []\n",
    "\n",
    "    uidx = int(user2idx[user_id])\n",
    "\n",
    "    # IMPORTANT for implicit==0.7.2: pass a single row for this user\n",
    "    user_items = X_ui[uidx]  # shape: (1, n_items)\n",
    "\n",
    "    item_idxs, _ = als_model.recommend(\n",
    "        userid=uidx,\n",
    "        user_items=user_items,\n",
    "        N=int(k),\n",
    "        filter_already_liked_items=bool(filter_already_liked),\n",
    "        recalculate_user=False,\n",
    "    )\n",
    "\n",
    "    # map internal -> external movie_id\n",
    "    out = []\n",
    "    for ii in item_idxs:\n",
    "        ii = int(ii)\n",
    "        if 0 <= ii < n_items:\n",
    "            out.append(int(idx2item[ii]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88de95b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:05:50,413] A new study created in memory with name: no-name-65835db7-e728-499f-ba53-9e354777e89c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb0ccc9fe2746f7b04f6525343a3bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:05:55,685] Trial 0 finished with value: 0.03952017998543702 and parameters: {'factors': 96, 'regularization': 0.0011075071617366523, 'alpha': 80, 'iterations': 30}. Best is trial 0 with value: 0.03952017998543702.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ccbe0ee20248179730705330367dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:00,387] Trial 1 finished with value: 0.04660575122005613 and parameters: {'factors': 192, 'regularization': 0.0012494932770966182, 'alpha': 40, 'iterations': 10}. Best is trial 1 with value: 0.04660575122005613.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e257d7bd230437e8f75971f484741b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:19,003] Trial 2 finished with value: 0.04744127447272047 and parameters: {'factors': 256, 'regularization': 0.01044247529427361, 'alpha': 40, 'iterations': 30}. Best is trial 2 with value: 0.04744127447272047.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70accd60a5f444fa0dc965b73566d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:23,761] Trial 3 finished with value: 0.04111195221293034 and parameters: {'factors': 192, 'regularization': 0.0032972945337534382, 'alpha': 80, 'iterations': 10}. Best is trial 2 with value: 0.04744127447272047.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ea8e816a6342d3811bb384cb6a0227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:33,556] Trial 4 finished with value: 0.05288756324770777 and parameters: {'factors': 192, 'regularization': 0.0467188938553891, 'alpha': 20, 'iterations': 20}. Best is trial 4 with value: 0.05288756324770777.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e1c3c5e05b4a1da20bf941310cdf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:36,265] Trial 5 finished with value: 0.04267591549668329 and parameters: {'factors': 64, 'regularization': 0.0018284964829724058, 'alpha': 40, 'iterations': 20}. Best is trial 4 with value: 0.05288756324770777.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043c6da578ca43b6b966f7748ade6124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:38,829] Trial 6 finished with value: 0.045547636572826254 and parameters: {'factors': 32, 'regularization': 0.0031449107576479243, 'alpha': 20, 'iterations': 30}. Best is trial 4 with value: 0.05288756324770777.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65b1f7a86fe47f385203605da97d3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:39,977] Trial 7 finished with value: 0.045673090965085 and parameters: {'factors': 32, 'regularization': 0.00030456667507209895, 'alpha': 20, 'iterations': 10}. Best is trial 4 with value: 0.05288756324770777.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4374c24aa8b64d4e93e11e8fac54fd02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:41,504] Trial 8 finished with value: 0.04737008279302246 and parameters: {'factors': 64, 'regularization': 0.02042993656910863, 'alpha': 20, 'iterations': 10}. Best is trial 4 with value: 0.05288756324770777.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab304a0e6dbe4fecaadf93cd9e7dec10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:43,078] Trial 9 finished with value: 0.04579478483671472 and parameters: {'factors': 64, 'regularization': 0.00017778542404624036, 'alpha': 20, 'iterations': 10}. Best is trial 4 with value: 0.05288756324770777.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a75a91569bf47a4831fd1ba839653af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:49,514] Trial 10 finished with value: 0.05310607053352458 and parameters: {'factors': 128, 'regularization': 0.04316722737064538, 'alpha': 5, 'iterations': 20}. Best is trial 10 with value: 0.05310607053352458.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b9ba26c6194a83b4614d497edecff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:06:55,181] Trial 11 finished with value: 0.05312342566326933 and parameters: {'factors': 128, 'regularization': 0.06653379503272186, 'alpha': 5, 'iterations': 20}. Best is trial 11 with value: 0.05312342566326933.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae86898d9f5a4fee8cde57cc3712b874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:07:01,506] Trial 12 finished with value: 0.05309173224752349 and parameters: {'factors': 128, 'regularization': 0.0990344832292094, 'alpha': 5, 'iterations': 20}. Best is trial 11 with value: 0.05312342566326933.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f046583fd19440ca342c2e5ca0d2e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:07:07,841] Trial 13 finished with value: 0.05325254443466865 and parameters: {'factors': 128, 'regularization': 0.017230728836731327, 'alpha': 5, 'iterations': 20}. Best is trial 13 with value: 0.05325254443466865.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4e3c1803004c859fd4040f34b78189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:07:13,357] Trial 14 finished with value: 0.051030799065805085 and parameters: {'factors': 128, 'regularization': 0.0162829207581793, 'alpha': 10, 'iterations': 20}. Best is trial 13 with value: 0.05325254443466865.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba52ba0b51f4bbdb3ae3f087f96a9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:07:18,772] Trial 15 finished with value: 0.05340069872554565 and parameters: {'factors': 128, 'regularization': 0.007495226929347601, 'alpha': 5, 'iterations': 20}. Best is trial 15 with value: 0.05340069872554565.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7ea2d11f554327b0c92ba3a18d6552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:07:23,969] Trial 16 finished with value: 0.053449644161059934 and parameters: {'factors': 128, 'regularization': 0.0066500797866162744, 'alpha': 5, 'iterations': 20}. Best is trial 16 with value: 0.053449644161059934.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a05880d8a046d78c5f9822af20852e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:07:36,891] Trial 17 finished with value: 0.04647311696533346 and parameters: {'factors': 256, 'regularization': 0.007799770297171023, 'alpha': 5, 'iterations': 20}. Best is trial 16 with value: 0.053449644161059934.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d67b49d6ead44a28a9058b2ec3985c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:07:40,491] Trial 18 finished with value: 0.0513910769965885 and parameters: {'factors': 96, 'regularization': 0.004999785294845281, 'alpha': 10, 'iterations': 20}. Best is trial 16 with value: 0.053449644161059934.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0556ba5800409db6b8f08691d8fcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:07:45,724] Trial 19 finished with value: 0.05286784827849279 and parameters: {'factors': 128, 'regularization': 0.0005706301747898778, 'alpha': 5, 'iterations': 20}. Best is trial 16 with value: 0.053449644161059934.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c6ed3708404a2eb2b314792d98260c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:07:53,452] Trial 20 finished with value: 0.05337835563810675 and parameters: {'factors': 128, 'regularization': 0.0065922104507297324, 'alpha': 5, 'iterations': 30}. Best is trial 16 with value: 0.053449644161059934.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a099afbd78744acc93b50d1599b39f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:08:01,079] Trial 21 finished with value: 0.05372007660475575 and parameters: {'factors': 128, 'regularization': 0.005562375053545441, 'alpha': 5, 'iterations': 30}. Best is trial 21 with value: 0.05372007660475575.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a557668b1642309395cd81ccef438e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:08:10,189] Trial 22 finished with value: 0.05309911733143443 and parameters: {'factors': 128, 'regularization': 0.0030862073457212195, 'alpha': 5, 'iterations': 30}. Best is trial 21 with value: 0.05372007660475575.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129d72b6d1234243858f82cac7b1db42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:08:18,346] Trial 23 finished with value: 0.053513308581102634 and parameters: {'factors': 128, 'regularization': 0.012405655911519476, 'alpha': 5, 'iterations': 30}. Best is trial 21 with value: 0.05372007660475575.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d96ab06d4644c3ab28739cc5c030330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:08:25,867] Trial 24 finished with value: 0.05305685352481291 and parameters: {'factors': 128, 'regularization': 0.025298357639481576, 'alpha': 5, 'iterations': 30}. Best is trial 21 with value: 0.05372007660475575.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0168b61361874599959e3dca6e229b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:08:33,396] Trial 25 finished with value: 0.042439995920283094 and parameters: {'factors': 128, 'regularization': 0.011488857153727865, 'alpha': 80, 'iterations': 30}. Best is trial 21 with value: 0.05372007660475575.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da73cfe4de0243dea5431510c83828b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:08:52,158] Trial 26 finished with value: 0.04695401767252721 and parameters: {'factors': 256, 'regularization': 0.00422725775747816, 'alpha': 5, 'iterations': 30}. Best is trial 21 with value: 0.05372007660475575.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14633d6810b345049e146f3dd4c962e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:08:57,586] Trial 27 finished with value: 0.05061312388454167 and parameters: {'factors': 96, 'regularization': 0.002084698885938155, 'alpha': 10, 'iterations': 30}. Best is trial 21 with value: 0.05372007660475575.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b182d4b3c1af475bb526b24b11cec883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:09:00,195] Trial 28 finished with value: 0.053713159760959084 and parameters: {'factors': 32, 'regularization': 0.03995199780790902, 'alpha': 5, 'iterations': 30}. Best is trial 21 with value: 0.05372007660475575.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda08947ef264b6f97d207025902f9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-16 22:09:03,209] Trial 29 finished with value: 0.034553386618388415 and parameters: {'factors': 32, 'regularization': 0.03157743546866435, 'alpha': 80, 'iterations': 30}. Best is trial 21 with value: 0.05372007660475575.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'factors': 128,\n",
       "  'regularization': 0.005562375053545441,\n",
       "  'alpha': 5,\n",
       "  'iterations': 30},\n",
       " 0.05372007660475575)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ui, artifacts = build_X_ui(train_df, threshold=4)\n",
    "n_users, n_items = X_ui.shape\n",
    "\n",
    "def objective(trial):\n",
    "    factors = trial.suggest_categorical(\"factors\", [32, 64, 96, 128, 192, 256])\n",
    "    reg = trial.suggest_float(\"regularization\", 1e-4, 1e-1, log=True)\n",
    "    alpha = trial.suggest_categorical(\"alpha\", [5, 10, 20, 40, 80])\n",
    "    iterations = trial.suggest_categorical(\"iterations\", [10, 20, 30])\n",
    "\n",
    "    # confidence scaling\n",
    "    X_ui_conf = (X_ui * alpha).tocsr()   # (n_users, n_items)\n",
    "\n",
    "    als = AlternatingLeastSquares(\n",
    "        factors=factors,\n",
    "        regularization=reg,\n",
    "        iterations=iterations,\n",
    "        random_state=42,\n",
    "    )\n",
    "    als.fit(X_ui_conf)\n",
    "\n",
    "    # sanity checks\n",
    "    assert als.user_factors.shape[0] == n_users\n",
    "    assert als.item_factors.shape[0] == n_items\n",
    "\n",
    "    def recommend(uid, k=10):\n",
    "        return recommend_als_from_artifacts(\n",
    "            als_model=als,\n",
    "            X_ui=X_ui_conf,     # <-- ВАЖНО: используем ту же матрицу, что и на fit()\n",
    "            artifacts=artifacts,\n",
    "            user_id=uid,\n",
    "            k=k,\n",
    "        )\n",
    "\n",
    "    metrics = evaluate_all(recommend, val_df, k=10)\n",
    "    return metrics[\"ndcg@10\"]\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "study.best_params, study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f3f88d",
   "metadata": {},
   "source": [
    "## Train model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06523684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840881d0d6384a4d8546940f26f253f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_codes, u_uniques = pd.factorize(train_pos[\"user_id\"], sort=True)\n",
    "i_codes, i_uniques = pd.factorize(train_pos[\"movie_id\"], sort=True)\n",
    "# X_ui: (n_users, n_items)\n",
    "n_users, n_items = X_ui.shape\n",
    "\n",
    "train_pos[\"u_idx\"] = u_codes.astype(np.int32)\n",
    "train_pos[\"i_idx\"] = i_codes.astype(np.int32)\n",
    "\n",
    "user2idx = pd.Series(np.arange(len(u_uniques)), index=u_uniques).to_dict()\n",
    "idx2user = pd.Series(u_uniques).to_dict()\n",
    "\n",
    "idx2item = pd.Series(i_uniques).to_dict()          # i_idx -> movie_id\n",
    "item2idx = pd.Series(np.arange(len(i_uniques)), index=i_uniques).to_dict()\n",
    "\n",
    "X_ui = csr_matrix(\n",
    "    (np.ones(len(train_pos), dtype=np.float32),\n",
    "     (train_pos[\"u_idx\"].to_numpy(), train_pos[\"i_idx\"].to_numpy())),\n",
    "    shape=(len(u_uniques), len(i_uniques)),\n",
    ")\n",
    "\n",
    "# item_users: (n_items, n_users)\n",
    "item_users = X_ui\n",
    "\n",
    "als_tune = AlternatingLeastSquares(\n",
    "    **{**study.best_params, 'random_state': 42}\n",
    ")\n",
    "\n",
    "als_tune.fit(item_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f7c4b",
   "metadata": {},
   "source": [
    "### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21962c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_als_tune(user_id: int, k: int = 10):\n",
    "    if user_id not in user2idx:\n",
    "        return []\n",
    "\n",
    "    uidx = user2idx[user_id]\n",
    "\n",
    "    seen_movie_ids = set(train_df.loc[train_df[\"user_id\"] == user_id, \"movie_id\"])\n",
    "    seen_iidx = {item2idx[m] for m in seen_movie_ids if m in item2idx}\n",
    "\n",
    "    item_idxs, scores = als_tune.recommend(uidx, X_ui[uidx], N=k + 200)\n",
    "\n",
    "    recs = []\n",
    "    n_items = X_ui.shape[1]\n",
    "\n",
    "    for ii in item_idxs:\n",
    "        ii = int(ii)\n",
    "\n",
    "        if ii < 0 or ii >= n_items:\n",
    "            raise RuntimeError(\n",
    "                f\"ALS returned out-of-range item index {ii}, but n_items={n_items}. \"\n",
    "                \"This means the model and X_ui are from different runs.\"\n",
    "            )\n",
    "\n",
    "        if ii in seen_iidx:\n",
    "            continue\n",
    "\n",
    "        recs.append(idx2item[ii])\n",
    "        if len(recs) == k:\n",
    "            break\n",
    "\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52ea7358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.011924485263221082 0.03727714748784441\n",
      "5 0.05116753706705084 0.04457763301162158\n",
      "10 0.09310282730055826 0.06357221786882399\n",
      "20 0.15306440962842907 0.08509533196596446\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 5, 10, 20]:\n",
    "    r, n = evaluate_model(recommend_als_tune, test_df, k=k)\n",
    "    print(k, r, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d924e41",
   "metadata": {},
   "source": [
    "### Practical Conclusion on Hyperparameter Optimization\n",
    "* Hyperparameter tuning with Optuna did not consistently outperform the baseline ALS model; metric differences are small and within evaluation noise.\n",
    "* The default ALS configuration already provides a strong and stable baseline for this dataset.\n",
    "* Optimizing a single metric (NDCG@10) does not guarantee improvements across other cutoffs (`Recall@5/10/20`).\n",
    "* As a result, the baseline ALS model was retained as the final model due to its simplicity, stability, and reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf26614",
   "metadata": {},
   "source": [
    "## Verifications\n",
    "\n",
    "### Qualitative Check: Inspecting Recommendations for a user\n",
    "\n",
    "This helper function is used for a qualitative sanity check of the recommendation model.\n",
    "\n",
    "Offline metrics (`Recall@K`, `NDCG@K`) show average performance, but they do not reveal what the model is actually recommending. \n",
    "\n",
    "Here we manually inspect recommendations for a single user and compare them to the user’s recent history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a552016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_recs_for_user(user_id: int, k: int = 10):\n",
    "    rec_ids = recommend_als(user_id, k=k)\n",
    "    rec_titles = movies_df.set_index(\"movie_id\").loc[rec_ids, \"title\"].tolist()\n",
    "\n",
    "    recent = (\n",
    "        train_df[train_df[\"user_id\"] == user_id]\n",
    "        .sort_values(\"timestamp\", ascending=False)\n",
    "        .head(10)\n",
    "        .merge(movies_df, on=\"movie_id\", how=\"left\")[[\"movie_id\",\"title\",\"rating\",\"timestamp\"]]\n",
    "    )\n",
    "\n",
    "    print(\"User:\", user_id)\n",
    "    print(\"\\nRecent history (train, last 10):\")\n",
    "    display(recent)\n",
    "\n",
    "    print(\"\\nRecommended:\")\n",
    "    for t in rec_titles:\n",
    "        print(\"-\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d610da62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 1\n",
      "\n",
      "Recent history (train, last 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>5</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>588</td>\n",
       "      <td>Aladdin (1992)</td>\n",
       "      <td>4</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>745</td>\n",
       "      <td>Close Shave, A (1995)</td>\n",
       "      <td>3</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2687</td>\n",
       "      <td>Tarzan (1999)</td>\n",
       "      <td>3</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595</td>\n",
       "      <td>Beauty and the Beast (1991)</td>\n",
       "      <td>5</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>527</td>\n",
       "      <td>Schindler's List (1993)</td>\n",
       "      <td>5</td>\n",
       "      <td>978824195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1545</td>\n",
       "      <td>Ponette (1996)</td>\n",
       "      <td>4</td>\n",
       "      <td>978824139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2398</td>\n",
       "      <td>Miracle on 34th Street (1947)</td>\n",
       "      <td>4</td>\n",
       "      <td>978302281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>594</td>\n",
       "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
       "      <td>4</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1197</td>\n",
       "      <td>Princess Bride, The (1987)</td>\n",
       "      <td>3</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                   title  rating  timestamp\n",
       "0         1                        Toy Story (1995)       5  978824268\n",
       "1       588                          Aladdin (1992)       4  978824268\n",
       "2       745                   Close Shave, A (1995)       3  978824268\n",
       "3      2687                           Tarzan (1999)       3  978824268\n",
       "4       595             Beauty and the Beast (1991)       5  978824268\n",
       "5       527                 Schindler's List (1993)       5  978824195\n",
       "6      1545                          Ponette (1996)       4  978824139\n",
       "7      2398           Miracle on 34th Street (1947)       4  978302281\n",
       "8       594  Snow White and the Seven Dwarfs (1937)       4  978302268\n",
       "9      1197              Princess Bride, The (1987)       3  978302268"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended:\n",
      "- Amadeus (1984)\n",
      "- Shawshank Redemption, The (1994)\n",
      "- Babe (1995)\n",
      "- Lion King, The (1994)\n",
      "- Bug's Life, A (1998)\n",
      "- It's a Wonderful Life (1946)\n",
      "- Shakespeare in Love (1998)\n",
      "- Fantasia (1940)\n",
      "- Ghostbusters (1984)\n",
      "- Peter Pan (1953)\n"
     ]
    }
   ],
   "source": [
    "show_recs_for_user(1, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4de6280f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, set())"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_no_seen(user_id: int, k: int = 20):\n",
    "    recs = recommend_als(user_id, k=k)\n",
    "    seen = set(train_df.loc[train_df[\"user_id\"] == user_id, \"movie_id\"])\n",
    "    overlap = set(recs) & seen\n",
    "    return len(overlap), overlap\n",
    "\n",
    "check_no_seen(1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b96481",
   "metadata": {},
   "source": [
    "### Evaluating Recall@10 by User Activity Bucket\n",
    "\n",
    "Users are grouped into **cold**, **medium**, and **warm** buckets based on the number of interactions they have in the training set.\n",
    "\n",
    "#### Step 1 — Define user activity buckets\n",
    "\n",
    "For each user, we count how many interactions they have in the training data and assign them to a bucket:\n",
    "\n",
    "* **cold**: fewer than 20 interactions\n",
    "* **medium**: 20–99 interactions\n",
    "* **warm**: 100 or more interactions\n",
    "\n",
    "This provides a simple proxy for how much information the model has about each user.\n",
    "\n",
    "#### Step 2 — Prepare test positives\n",
    "\n",
    "Explicit ratings in the test set are converted into implicit feedback by treating ratings ≥ 4 as positive interactions.\n",
    "Only these positive test interactions are used for evaluation, following the standard implicit-feedback evaluation protocol.\n",
    "\n",
    "#### Step 3 — Compute user-level Recall@10\n",
    "\n",
    "For each user with at least one positive test interaction:\n",
    "1. The ALS model generates top-10 recommendations.\n",
    "2. Recall@10 is computed as the fraction of the user’s relevant test items that appear in the recommendation list:\n",
    "\n",
    "$$\n",
    "\\huge Recall@10(u) = \\frac{|Recommended_{10}(u) \\cap Relevant(u)|}{|Relevant(u)|}\n",
    "$$\n",
    "\n",
    "3. Each user’s recall value is stored together with their activity bucket.\n",
    "\n",
    "#### Step 4 - Aggregate results by bucket\n",
    "\n",
    "Finally, `Recall@10` values are averaged within each bucket to obtain mean recall scores for cold, medium, and warm users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f29bb91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bucket\n",
       "cold      0.128154\n",
       "medium    0.110225\n",
       "warm      0.071552\n",
       "Name: recall, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_len = train_df.groupby(\"user_id\").size()\n",
    "\n",
    "def bucket(u):\n",
    "    n = hist_len.get(u, 0)\n",
    "    if n < 20: return \"cold\"\n",
    "    if n < 100: return \"medium\"\n",
    "    return \"warm\"\n",
    "\n",
    "tmp = test_df.copy()\n",
    "tmp[\"interaction\"] = (tmp[\"rating\"] >= 4).astype(int)\n",
    "test_pos = tmp[tmp[\"interaction\"] == 1]\n",
    "\n",
    "rows = []\n",
    "for user_id, g in test_pos.groupby(\"user_id\"):\n",
    "    recs = recommend_als(user_id, k=10)\n",
    "    if not recs:\n",
    "        continue\n",
    "    relevant = g[\"movie_id\"].tolist()\n",
    "    r = len(set(recs) & set(relevant)) / len(relevant)\n",
    "    rows.append((bucket(user_id), r))\n",
    "\n",
    "pd.DataFrame(rows, columns=[\"bucket\", \"recall\"]).groupby(\"bucket\")[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca74b82",
   "metadata": {},
   "source": [
    "### Item-to-Item Similarity: Finding Movies Similar to a Given Movie (ALS Embeddings)\n",
    "\n",
    "Since ALS learns a latent vector (embedding) for each movie, we can treat movies as “similar” if their embeddings point in a similar direction in the latent space.\n",
    "\n",
    "This is a **qualitative sanity check** showing that the latent space learned by ALS captures meaningful collaborative structure:\n",
    "movies that are frequently co-liked by similar users end up close to each other, resulting in intuitive “similar movies” lists.\n",
    "\n",
    "This item-to-item similarity view is also practically useful:\n",
    "* for “Because you watched X” recommendations,\n",
    "* for building candidate sets in a retrieval stage,\n",
    "* and for model debugging (spotting obviously wrong neighbors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71ca18b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toy Story 2 (1999)',\n",
       " \"Bug's Life, A (1998)\",\n",
       " 'Babe (1995)',\n",
       " 'Aladdin (1992)',\n",
       " 'Groundhog Day (1993)',\n",
       " 'Lion King, The (1994)',\n",
       " 'Saving Private Ryan (1998)',\n",
       " 'Wrong Trousers, The (1993)',\n",
       " 'Beauty and the Beast (1991)',\n",
       " 'Shakespeare in Love (1998)']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def similar_movies(movie_id: int, topn: int = 10):\n",
    "    if movie_id not in item2idx:\n",
    "        return None\n",
    "    i = item2idx[movie_id]\n",
    "    v = als.item_factors[i]\n",
    "    sims = als.item_factors @ v\n",
    "    best = np.argpartition(-sims, topn+1)[:topn+1]\n",
    "    best = best[np.argsort(-sims[best])]\n",
    "    best_movie_ids = [idx2item[int(j)] for j in best if int(j) != i][:topn]\n",
    "    return movies_df.set_index(\"movie_id\").loc[best_movie_ids, \"title\"].tolist()\n",
    "\n",
    "similar_movies(1, 10)  # Toy Story"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c43b9",
   "metadata": {},
   "source": [
    "### Per-User Recall Analysis\n",
    "\n",
    "It computes **Recall@K for each user individually**, enriches it with the user’s training-history size, assigns an activity bucket (cold/medium/warm), and saves the resulting dataset for further analysis and visualization.\n",
    "\n",
    "The function treats ratings as **implicit feedback** by defining positive interactions as rating >= threshold (by default, threshold = 4). \n",
    "First, it extracts the positive interactions from the **training split** and counts them per user (n_pos_train). \n",
    "This count serves as a proxy for how much behavioral data is available to the model for each user. \n",
    "Next, it processes **the test split** by converting ratings into a binary interaction label and keeping only the positive test interactions. \n",
    "These positive test items for each user represent the “relevant” set used in ranking evaluation.\n",
    "\n",
    "For each user who has at least one positive test interaction, the function calls the provided recommendation function to generate the top-K recommendations and computes **user-level Recall@K** as the fraction of the relevant test items that appear in the recommendation list. Users for whom the recommender returns no results are skipped to avoid misleading zeros caused by missing mappings or cold-start users outside the training vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "570069d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_user_recall_df(\n",
    "    recommend_fn,\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    k: int = 10,\n",
    "    threshold: int = 4,\n",
    "):\n",
    "    train_pos = train_df[train_df[\"rating\"] >= threshold]\n",
    "    pos_len = train_pos.groupby(\"user_id\").size()\n",
    "\n",
    "    tmp = test_df.copy()\n",
    "    tmp[\"interaction\"] = (tmp[\"rating\"] >= threshold).astype(np.int8)\n",
    "    test_pos = tmp[tmp[\"interaction\"] == 1]\n",
    "\n",
    "    rows = []\n",
    "    for user_id, g in test_pos.groupby(\"user_id\"):\n",
    "        relevant = g[\"movie_id\"].tolist()\n",
    "        recs = recommend_fn(user_id, k=k)\n",
    "\n",
    "        if not recs or len(relevant) == 0:\n",
    "            continue\n",
    "\n",
    "        recall = len(set(recs) & set(relevant)) / len(relevant)\n",
    "        n_pos = int(pos_len.get(user_id, 0))\n",
    "\n",
    "        if n_pos < 10:\n",
    "            bucket = \"cold\"\n",
    "        elif n_pos < 50:\n",
    "            bucket = \"medium\"\n",
    "        else:\n",
    "            bucket = \"warm\"\n",
    "\n",
    "        rows.append({\"user_id\": user_id, \"recall\": recall, \"n_pos_train\": n_pos, \"bucket\": bucket})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_user = per_user_recall_df(recommend_als, train_df, test_df, k=10, threshold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19362011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Recall@10 by bucket:\n",
      "bucket\n",
      "cold      0.111137\n",
      "medium    0.122509\n",
      "warm      0.070342\n",
      "Name: recall, dtype: float64\n",
      "\n",
      "Users per bucket:\n",
      "bucket\n",
      "cold       217\n",
      "medium    2425\n",
      "warm      2911\n",
      "Name: user_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "group_means = df_user.groupby(\"bucket\")[\"recall\"].mean().sort_index()\n",
    "group_counts = df_user.groupby(\"bucket\")[\"user_id\"].count().sort_index()\n",
    "\n",
    "print(\"Mean Recall@10 by bucket:\")\n",
    "print(group_means)\n",
    "\n",
    "print(\"\\nUsers per bucket:\")\n",
    "print(group_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9301a9",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "The evaluation is split into two groups of metrics:\n",
    "\n",
    "(1) Ranking quality metrics (user-level, averaged over users) — these measure how well the recommender ranks items that the user actually liked in the test period. For each user, the relevant set is defined as items with positive interactions in the test split, and the model is asked to produce top-K recommendations. The metrics are then computed for each user and averaged across all evaluated users.\n",
    "* `Recall@K`: measures how many of the user’s relevant items were retrieved in the top-K. It focuses on coverage of relevant items, not their order. Higher Recall@K means the model is better at “finding” relevant items, but it does not strongly reward putting the best items near the top.\n",
    "* `NDCG@K`: measures ranking quality with position discounts. Hits at the top of the list contribute more than hits at the bottom. NDCG is normalized by the best possible ranking for that user, so it is comparable across users with different numbers of relevant items. Higher NDCG@K indicates better ordering of relevant items near the top.\n",
    "* `MRR@K` (Mean Reciprocal Rank): measures how early the first relevant item appears in the top-K. If the first relevant item is at rank 1, MRR=1; at rank 5, MRR=0.2; and if there are no hits in top-K, MRR=0. MRR is especially useful when you care about “at least one good item appears quickly”.\n",
    "* `HitRate@K`: measures whether there is at least one relevant item in the top-K (binary per user). It ignores how many relevant items were retrieved and where they appear beyond the first hit. This metric is particularly common in leave-one-out evaluation setups (when each user has exactly one relevant item in test), where HitRate@K becomes equivalent to Recall@K.\n",
    "* `n_users_eval`: the number of users actually included in the metric computation. Users with no positive test interactions or users for whom the recommender returns no recommendations are skipped, and this field tells you how large the evaluated population is.\n",
    "\n",
    "(2) Catalog/behavior metrics (global, model-level) — these describe recommendation behavior beyond accuracy.\n",
    "* `Coverage@K`: measures how diverse the recommender is across the catalog. It is computed as the fraction of unique items ever recommended (across a set of users) divided by the total catalog size. Higher Coverage@K means the model recommends a broader range of items, while low coverage indicates that recommendations concentrate on a small subset of the catalog.\n",
    "* `AvgPopularity@K`: measures popularity bias in recommendations. It computes the average popularity score of all recommended items (across users), where popularity can be defined as the number of interactions in training (or any similar count-based score). Higher values indicate that the model mostly recommends already-popular items; lower values indicate that the model recommends more niche/long-tail items.\n",
    "\n",
    "The final output dictionary aggregates all computed metrics in a single standardized format (e.g., recall@10, ndcg@10, etc.), enabling direct comparison of different models under the same evaluation protocol and the same top-K cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5dbd24b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@10': 0.09471757008223783,\n",
       " 'ndcg@10': 0.0656072331693472,\n",
       " 'mrr@10': 0.09186833086076739,\n",
       " 'hitrate@10': 0.24959481361426256,\n",
       " 'n_users_eval': 5553,\n",
       " 'coverage@10': 0.1733195982487767,\n",
       " 'avg_popularity@10': 992.1976}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_als_fn = lambda uid, k: recommend_als(uid, k=k)\n",
    "metrics_als = evaluate_all(\n",
    "    recommend_als_fn,\n",
    "    test_df,\n",
    "    users_for_coverage=test_df[\"user_id\"].unique()[:1000],\n",
    "    all_items=movies_df[\"movie_id\"].unique(),\n",
    "    item_popularity=item_popularity.to_dict(),\n",
    "    k=10,\n",
    ")\n",
    "metrics_als"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1be62f",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61fe1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "als.save(\n",
    "    os.path.join(MODELS, \"alternating_least_squares\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recommendation system (MovieLens)",
   "language": "python",
   "name": "movielens-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
